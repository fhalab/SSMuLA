{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/disk2/fli/SSMuLA\n"
     ]
    }
   ],
   "source": [
    "%cd ~/SSMuLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext blackcellmagic\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SSMuLA.preprocess import ProcessDHFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SSMuLA.preprocess.ProcessDHFR at 0x7f896ee3afb0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ProcessDHFR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "    <style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"c6bdb781-3be8-47b7-9d28-f6cb2897980d\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    function drop(id) {\n      const view = Bokeh.index.get_by_id(id)\n      if (view != null) {\n        view.model.document.clear()\n        Bokeh.index.delete(view)\n      }\n    }\n\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n\n    // Clean up Bokeh references\n    if (id != null) {\n      drop(id)\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim()\n            drop(id)\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"c6bdb781-3be8-47b7-9d28-f6cb2897980d\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.3.4.min.js\", \"https://unpkg.com/@holoviz/panel@1.3.8/dist/panel.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"c6bdb781-3be8-47b7-9d28-f6cb2897980d\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from Bio.Seq import Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import datetime\n",
    "import pathlib\n",
    "\n",
    "# Data manipulation\n",
    "# import growth_analysis as ga\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 40)\n",
    "import numpy as np\n",
    "\n",
    "# Basic plotting\n",
    "import holoviews as hv\n",
    "import bokeh\n",
    "from bokeh.io import export_svg\n",
    "from bokeh.themes.theme import Theme\n",
    "theme = Theme(\n",
    "    json = {\n",
    "    'attrs' : {\n",
    "        'Title': {\n",
    "            'align':'center',\n",
    "            'text_font_size':'15px',\n",
    "            'text_color':'black',\n",
    "            'text_font': 'arial'\n",
    "        },       # title centered and bigger\n",
    "        'Axis': {\n",
    "            'axis_label_text_font_style': 'normal',\n",
    "            'axis_label_text_color':'black',\n",
    "            'major_label_text_color':'black',\n",
    "            'axis_label_text_font': 'arial',\n",
    "            'major_label_text_font': 'arial',\n",
    "        },          # no italic labels \n",
    "        'Legend': {\n",
    "            'title_text_font_style': 'normal',\n",
    "            'title_text_color':'black',\n",
    "            'label_text_color':'black',\n",
    "            'label_text_font': 'arial',\n",
    "        },\n",
    "        'ColorBar': {\n",
    "            'title_text_font_style': 'normal',\n",
    "            'major_label_text_color':'black',\n",
    "            'major_label_text_font': 'arial',\n",
    "            'title_text_color':'black',\n",
    "            'title_text_font': 'arial',\n",
    "        },\n",
    "    }\n",
    "}\n",
    ")\n",
    "\n",
    "hv.extension('bokeh')\n",
    "hv.renderer('bokeh').theme = theme\n",
    "\n",
    "import panel as pn\n",
    "pn.config.comms = \"vscode\"\n",
    "\n",
    "# Large data plotting\n",
    "import datashader as ds\n",
    "from holoviews.operation.datashader import datashade, rasterize\n",
    "\n",
    "# Making graphs\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from tqdm.auto import tqdm\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from SSMuLA.landscape_global import ACTIVE_THRESH_DICT, LIB_INFO_DICT, calc_active_cutoff\n",
    "from SSMuLA.vis import save_bokeh_hv, CODON_AA_COLOER_DICT, plot_fit_dist\n",
    "from SSMuLA.util import checkNgen_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcessDHFR:\n",
    "    \"\"\"\n",
    "    Class to clean up the DHFR data\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_csv: str = \"data/DHFR/fitness_landscape/DHFR.csv\") -> None:\n",
    "\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - input_csv, str: path to the input csv file\n",
    "        \"\"\"\n",
    "\n",
    "        self._input_csv = input_csv\n",
    "\n",
    "        # append the active cutoffs\n",
    "        self._df_avg_aa_append, self._avg_aa_active_cutoff = calc_active_cutoff(\n",
    "            self.df_avg_aa, [\"fitness\"]\n",
    "        )\n",
    "\n",
    "        # save the appended dataframe\n",
    "        self._df_avg_aa_append.to_csv(self.output_csv, index=False)\n",
    "\n",
    "        self._overlay_fit_dist()\n",
    "\n",
    "    def _overlay_fit_dist(\n",
    "        self,\n",
    "        title: str = \"DHFR fitness distribution\",\n",
    "    ) -> hv.Distribution:\n",
    "        \n",
    "        \"\"\"\n",
    "        Plot the fitness distribution\n",
    "\n",
    "        Args:\n",
    "        - dist1, hv.Distribution: fitness distribution 1\n",
    "        - dist2, hv.Distribution: fitness distribution 2\n",
    "        - active_cut_calc, float: calculated active cutoff\n",
    "        - active_cut_def, float: defined active cutoff\n",
    "\n",
    "        Returns:\n",
    "        - hv.Distribution: plot of the fitness distribution\n",
    "        \"\"\"\n",
    "\n",
    "        # Overlay the two plots\n",
    "        overlay_dist = (\n",
    "            self.codon_fit_dist\n",
    "            * self.avg_aa_fit_dist\n",
    "            * hv.Spikes([self.avg_aa_active_cutoff], label = \"Calculated active cutoff\").opts(\n",
    "                color=\"gray\", line_width=1.6\n",
    "            )\n",
    "            * hv.Spikes([ACTIVE_THRESH_DICT[\"DHFR\"]], label = \"Defined active cutoff\").opts(\n",
    "                color=\"gray\", line_dash=\"dashed\", line_width=1.6\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Customize the plot options\n",
    "        overlay_dist.opts(\n",
    "            legend_position=\"top_right\",\n",
    "            title=title,\n",
    "            xlabel=\"Fitness\",\n",
    "        )\n",
    "\n",
    "        # Display the plot with the legend\n",
    "        save_bokeh_hv(\n",
    "            overlay_dist,\n",
    "            plot_name=title,\n",
    "            plot_path=\"results/fitness_distribution\",\n",
    "            bokehorhv=\"hv\",\n",
    "        )\n",
    "        return overlay_dist\n",
    "\n",
    "    @property\n",
    "    def lib_info(self) -> dict:\n",
    "        \"\"\"Return the library information\"\"\"\n",
    "        return LIB_INFO_DICT[\"DHFR\"]\n",
    "\n",
    "    @property\n",
    "    def split_AA_cols(self) -> list:\n",
    "        \"\"\"Return the columns for the split amino acids\"\"\"\n",
    "        return [f\"AA{str(i)}\" for i in self.lib_info[\"positions\"].keys()]\n",
    "\n",
    "    @property\n",
    "    def input_df(self) -> pd.DataFrame:\n",
    "        \"\"\"Return the input dataframe\"\"\"\n",
    "        return pd.read_csv(self._input_csv)\n",
    "\n",
    "    @property\n",
    "    def df_aa(self) -> pd.DataFrame:\n",
    "\n",
    "        \"\"\"Return the input dataframe with amino acid translations\"\"\"\n",
    "\n",
    "        df = self.input_df.copy()\n",
    "\n",
    "        # Translate the sequence to amino acids\n",
    "        df[\"AAs\"] = df[\"seq\"].apply(lambda x: \"\".join(Seq(x).translate()))\n",
    "\n",
    "        return df[[\"AAs\", \"seq\", \"fitness\"]].copy()\n",
    "\n",
    "    @property\n",
    "    def df_split_aa(self) -> pd.DataFrame:\n",
    "\n",
    "        \"\"\"Return the input dataframe with amino acid translations\n",
    "        and split into individual amino acids\"\"\"\n",
    "\n",
    "        df = self.df_aa.copy()\n",
    "\n",
    "        # Split combo into individual amino acids\n",
    "        df[self.split_AA_cols] = df[\"AAs\"].apply(lambda x: pd.Series(list(x)))\n",
    "\n",
    "        return df[[\"AAs\", *self.split_AA_cols, \"seq\", \"fitness\"]].copy()\n",
    "\n",
    "    @property\n",
    "    def df_avg_aa(self) -> pd.DataFrame:\n",
    "\n",
    "        \"\"\"Return the average fitness of each amino acid\"\"\"\n",
    "\n",
    "        df = self.df_aa.copy()[[\"AAs\", \"fitness\"]]\n",
    "        # Group by amino acid and take the average fitness\n",
    "        df = df.groupby(\"AAs\")[\"fitness\"].mean().reset_index()\n",
    "        # Split combo into individual amino acids\n",
    "        df[self.split_AA_cols] = df[\"AAs\"].apply(lambda x: pd.Series(list(x)))\n",
    "        return df[[\"AAs\", *self.split_AA_cols, \"fitness\"]].copy()\n",
    "\n",
    "    @property\n",
    "    def df_avg_aa_append(self) -> pd.DataFrame:\n",
    "        \"\"\"Return the average fitness of each amino acid with the active cutoff appended\"\"\"\n",
    "        return self._df_avg_aa_append\n",
    "\n",
    "    @property\n",
    "    def avg_aa_active_cutoff(self) -> float:\n",
    "        \"\"\"Return the active cutoff for the average amino acid\"\"\"\n",
    "        return self._avg_aa_active_cutoff\n",
    "\n",
    "    @property\n",
    "    def codon_fit(self) -> pd.Series:\n",
    "        \"\"\"Return the fitness of based on codon as a series\"\"\"\n",
    "        return self.input_df[\"fitness\"]\n",
    "\n",
    "    @property\n",
    "    def avg_aa_fit(self) -> pd.Series:\n",
    "        \"\"\"Return the fitness of based on codon as a series\"\"\"\n",
    "        return self.df_avg_aa[\"fitness\"]\n",
    "\n",
    "    @property\n",
    "    def codon_fit_dist(self) -> hv.Distribution:\n",
    "        \"\"\"Return the fitness distribution based on codon\"\"\"\n",
    "        return plot_fit_dist(self.codon_fit, \"codon\")\n",
    "\n",
    "    @property\n",
    "    def avg_aa_fit_dist(self) -> hv.Distribution:\n",
    "        \"\"\"Return the fitness distribution based on average amino acid\"\"\"\n",
    "        return plot_fit_dist(self.avg_aa_fit, \"AA\")\n",
    "    \n",
    "    @property\n",
    "    def output_csv(self) -> str:\n",
    "        \"\"\"Return the path to the output csv\"\"\"\n",
    "        output_csv = self._input_csv.replace(\"fitness_landscape\", \"processed\")\n",
    "        # check if the folder exists\n",
    "        checkNgen_folder(output_csv)\n",
    "        return output_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ProcessDHFR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkNgen_folder(\"data/DHFR/fitness_landscape/DHFR.csv\".replace(\"fitness_landscape\", \"processed\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_active_cutoff(\n",
    "    df=avg_aa_df, fitness_cols = [\"fitness\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_aa_df['active'].value_counts()/len(avg_aa_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ProcessDHFR().df_avg_aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ProcessDHFR().input_df[\"seq\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhfr_fitclass = ProcessDHFR()\n",
    "\n",
    "codon_df = ProcessDHFR().input_df\n",
    "avg_aa_df = ProcessDHFR().df_avg_aa\n",
    "\n",
    "codon_fit = codon_df[\"fitness\"]\n",
    "aa_fit = avg_aa_df[\"fitness\"]\n",
    "\n",
    "# Create the first distribution plot\n",
    "condon_dist = (\n",
    "    hv.Distribution(codon_fit, label=\"Codon-level\").opts(\n",
    "        width=400,\n",
    "        height=400,\n",
    "        color=PRESENTATION_PALETTE_SATURATE6[\"blue\"],\n",
    "        line_color=None,\n",
    "    )\n",
    "    * hv.Spikes([codon_fit.mean()], label=\"Mean codon fitness\").opts(\n",
    "        line_dash=\"dotted\", line_color=PRESENTATION_PALETTE_SATURATE6[\"blue\"], line_width=1.6\n",
    "    )  # for label\n",
    "    * hv.Spikes([codon_fit.median()], label=\"Median codon fitness\").opts(\n",
    "        line_color=PRESENTATION_PALETTE_SATURATE6[\"blue\"], line_width=1.6\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create the second distribution plot\n",
    "aa_dist = (\n",
    "    hv.Distribution(aa_fit, label=\"AA-level\").opts(\n",
    "        color=PRESENTATION_PALETTE_SATURATE6[\"orange\"],\n",
    "        line_color=None,\n",
    "    )\n",
    "    * hv.Spikes([aa_fit.mean()], label=\"Mean AA fitness\").opts(\n",
    "        line_dash=\"dotted\", line_color=PRESENTATION_PALETTE_SATURATE6[\"orange\"], line_width=1.6\n",
    "    )\n",
    "    * hv.Spikes([aa_fit.median()], label=\"Median AA fitness\").opts(\n",
    "        line_color=PRESENTATION_PALETTE_SATURATE6[\"orange\"], line_width=1.6\n",
    "    )\n",
    ")\n",
    "\n",
    "# Overlay the two plots\n",
    "overlay_dist = dist1 * dist2\n",
    "\n",
    "# Customize the plot options\n",
    "overlay_dist.opts(\n",
    "    legend_position=\"top_right\",\n",
    "    title=\"DHFR fitness distribution\",\n",
    "    xlabel=\"Fitness\",\n",
    ")  # ylabel='Frequency')\n",
    "\n",
    "# Display the plot with the legend\n",
    "save_bokeh_hv(\n",
    "    overlay_dist,\n",
    "    plot_name=\"DHFR fitness distribution\",\n",
    "    plot_path=\"results/fitness_distribution\",\n",
    "    bokehorhv = \"hv\",\n",
    "    # dpi: int = 300,\n",
    "    # scale: float = 1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_split_aa = ProcessDHFR().df_split_aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_counts = df_split_aa.groupby([\"AAs\", \"AA1\", \"AA2\", \"AA3\"], as_index=True).count().reset_index()\n",
    "site_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SSMuLA.param import TRANSLATE_DICT, CODON_COUNT_PER_AA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_split_aa['Counts'] = df_split_aa.groupby('AAs')[\"AAs\"].transform('count')\n",
    "count_aa = df_split_aa[[\"AAs\", \"AA1\", \"AA2\", \"AA3\", \"Counts\"]].drop_duplicates().sort_values(\"AAs\").reset_index(drop=True)\n",
    "count_aa[\"Norm_counts\"] = count_aa.apply(lambda row: row[\"Counts\"] / (CODON_COUNT_PER_AA[row[\"AA1\"]] * CODON_COUNT_PER_AA[row[\"AA2\"]] * CODON_COUNT_PER_AA[row[\"AA3\"]]), axis=1)\n",
    "count_aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_aa.Norm_counts.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_counts_df = site_counts.to_frame()\n",
    "site_counts_df.plot(kind='bar', figsize=(20, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_stop_df = avg_aa_df[avg_aa_df[\"AAs\"].str.contains(\"\\*\")]\n",
    "aa_stop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc active vs inactive based on 1.96 std > mean fitness\n",
    "\n",
    "avg_stop = aa_stop_df[\"fitness\"].mean()\n",
    "std_stop = aa_stop_df[\"fitness\"].std()\n",
    "fit_min = 1.96 * std_stop + avg_stop\n",
    "\n",
    "print('95%', len(avg_aa_df.loc[avg_aa_df['fitness'] > fit_min]), fit_min)\n",
    "\n",
    "# add column called active if fitness > fit_min\n",
    "avg_aa_df.loc[avg_aa_df['fitness'] > fit_min, 'active'] = True\n",
    "avg_aa_df.loc[avg_aa_df['fitness'] <= fit_min, 'active'] = False\n",
    "avg_aa_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# active percentage\n",
    "active_percnet = avg_aa_df['active'].value_counts()/len(avg_aa_df)\n",
    "active_percnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_min"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SSMuLA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
