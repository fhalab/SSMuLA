{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/disk2/fli/SSMuLA\n"
     ]
    }
   ],
   "source": [
    "%cd ~/SSMuLA/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import atom3d.datasets as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load dataset from directory of PDB files\n",
    "dataset = da.load_dataset(\"data/ParD3/ParD3.pdb\", 'pdb')\n",
    "# Create LMDB dataset from PDB dataset\n",
    "da.make_lmdb_dataset(dataset, \"lmdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, functools\n",
    "from torch import nn, scatter_add\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import MessagePassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuple_sum(*args):\n",
    "    '''\n",
    "    Sums any number of tuples (s, V) elementwise.\n",
    "    '''\n",
    "    return tuple(map(sum, zip(*args)))\n",
    "\n",
    "\n",
    "def tuple_cat(*args, dim=-1):\n",
    "    '''\n",
    "    Concatenates any number of tuples (s, V) elementwise.\n",
    "    \n",
    "    :param dim: dimension along which to concatenate when viewed\n",
    "                as the `dim` index for the scalar-channel tensors.\n",
    "                This means that `dim=-1` will be applied as\n",
    "                `dim=-2` for the vector-channel tensors.\n",
    "    '''\n",
    "    dim %= len(args[0][0].shape)\n",
    "    s_args, v_args = list(zip(*args))\n",
    "    return torch.cat(s_args, dim=dim), torch.cat(v_args, dim=dim)\n",
    "\n",
    "\n",
    "def tuple_index(x, idx):\n",
    "    '''\n",
    "    Indexes into a tuple (s, V) along the first dimension.\n",
    "    \n",
    "    :param idx: any object which can be used to index into a `torch.Tensor`\n",
    "    '''\n",
    "    return x[0][idx], x[1][idx]\n",
    "\n",
    "def _split(x, nv):\n",
    "    '''\n",
    "    Splits a merged representation of (s, V) back into a tuple. \n",
    "    Should be used only with `_merge(s, V)` and only if the tuple \n",
    "    representation cannot be used.\n",
    "    \n",
    "    :param x: the `torch.Tensor` returned from `_merge`\n",
    "    :param nv: the number of vector channels in the input to `_merge`\n",
    "    '''\n",
    "    v = torch.reshape(x[..., -3*nv:], x.shape[:-1] + (nv, 3))\n",
    "    s = x[..., :-3*nv]\n",
    "    return s, v\n",
    "\n",
    "def _merge(s, v):\n",
    "    '''\n",
    "    Merges a tuple (s, V) into a single `torch.Tensor`, where the\n",
    "    vector channels are flattened and appended to the scalar channels.\n",
    "    Should be used only if the tuple representation cannot be used.\n",
    "    Use `_split(x, nv)` to reverse.\n",
    "    '''\n",
    "    v = torch.reshape(v, v.shape[:-2] + (3*v.shape[-2],))\n",
    "    return torch.cat([s, v], -1)\n",
    "\n",
    "def _norm_no_nan(x, axis=-1, keepdims=False, eps=1e-8, sqrt=True):\n",
    "    '''\n",
    "    L2 norm of tensor clamped above a minimum value `eps`.\n",
    "    \n",
    "    :param sqrt: if `False`, returns the square of the L2 norm\n",
    "    '''\n",
    "    out = torch.clamp(torch.sum(torch.square(x), axis, keepdims), min=eps)\n",
    "    return torch.sqrt(out) if sqrt else out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _VDropout(nn.Module):\n",
    "    '''\n",
    "    Vector channel dropout where the elements of each\n",
    "    vector channel are dropped together.\n",
    "    '''\n",
    "    def __init__(self, drop_rate):\n",
    "        super(_VDropout, self).__init__()\n",
    "        self.drop_rate = drop_rate\n",
    "        self.dummy_param = nn.Parameter(torch.empty(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        :param x: `torch.Tensor` corresponding to vector channels\n",
    "        '''\n",
    "        device = self.dummy_param.device\n",
    "        if not self.training:\n",
    "            return x\n",
    "        mask = torch.bernoulli(\n",
    "            (1 - self.drop_rate) * torch.ones(x.shape[:-1], device=device)\n",
    "        ).unsqueeze(-1)\n",
    "        x = mask * x / (1 - self.drop_rate)\n",
    "        return x\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    '''\n",
    "    Combined LayerNorm for tuples (s, V).\n",
    "    Takes tuples (s, V) as input and as output.\n",
    "    '''\n",
    "    def __init__(self, dims):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.s, self.v = dims\n",
    "        self.scalar_norm = nn.LayerNorm(self.s)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        :param x: tuple (s, V) of `torch.Tensor`,\n",
    "                  or single `torch.Tensor` \n",
    "                  (will be assumed to be scalar channels)\n",
    "        '''\n",
    "        if not self.v:\n",
    "            return self.scalar_norm(x)\n",
    "        s, v = x\n",
    "        vn = _norm_no_nan(v, axis=-1, keepdims=True, sqrt=False)\n",
    "        vn = torch.sqrt(torch.mean(vn, dim=-2, keepdim=True))\n",
    "        return self.scalar_norm(s), v / vn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Dropout(nn.Module):\n",
    "    '''\n",
    "    Combined dropout for tuples (s, V).\n",
    "    Takes tuples (s, V) as input and as output.\n",
    "    '''\n",
    "    def __init__(self, drop_rate):\n",
    "        super(Dropout, self).__init__()\n",
    "        self.sdropout = nn.Dropout(drop_rate)\n",
    "        self.vdropout = _VDropout(drop_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        :param x: tuple (s, V) of `torch.Tensor`,\n",
    "                  or single `torch.Tensor` \n",
    "                  (will be assumed to be scalar channels)\n",
    "        '''\n",
    "        if type(x) is torch.Tensor:\n",
    "            return self.sdropout(x)\n",
    "        s, v = x\n",
    "        return self.sdropout(s), self.vdropout(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GVP(nn.Module):\n",
    "    '''\n",
    "    Geometric Vector Perceptron. See manuscript and README.md\n",
    "    for more details.\n",
    "    \n",
    "    :param in_dims: tuple (n_scalar, n_vector)\n",
    "    :param out_dims: tuple (n_scalar, n_vector)\n",
    "    :param h_dim: intermediate number of vector channels, optional\n",
    "    :param activations: tuple of functions (scalar_act, vector_act)\n",
    "    :param vector_gate: whether to use vector gating.\n",
    "                        (vector_act will be used as sigma^+ in vector gating if `True`)\n",
    "    '''\n",
    "    def __init__(self, in_dims, out_dims, h_dim=None,\n",
    "                 activations=(F.relu, torch.sigmoid), vector_gate=False):\n",
    "        super(GVP, self).__init__()\n",
    "        self.si, self.vi = in_dims\n",
    "        self.so, self.vo = out_dims\n",
    "        self.vector_gate = vector_gate\n",
    "        if self.vi: \n",
    "            self.h_dim = h_dim or max(self.vi, self.vo) \n",
    "            self.wh = nn.Linear(self.vi, self.h_dim, bias=False)\n",
    "            self.ws = nn.Linear(self.h_dim + self.si, self.so)\n",
    "            if self.vo:\n",
    "                self.wv = nn.Linear(self.h_dim, self.vo, bias=False)\n",
    "                if self.vector_gate: self.wsv = nn.Linear(self.so, self.vo)\n",
    "        else:\n",
    "            self.ws = nn.Linear(self.si, self.so)\n",
    "        \n",
    "        self.scalar_act, self.vector_act = activations\n",
    "        self.dummy_param = nn.Parameter(torch.empty(0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        :param x: tuple (s, V) of `torch.Tensor`, \n",
    "                  or (if vectors_in is 0), a single `torch.Tensor`\n",
    "        :return: tuple (s, V) of `torch.Tensor`,\n",
    "                 or (if vectors_out is 0), a single `torch.Tensor`\n",
    "        '''\n",
    "        if self.vi:\n",
    "            s, v = x\n",
    "            v = torch.transpose(v, -1, -2)\n",
    "            vh = self.wh(v)    \n",
    "            vn = _norm_no_nan(vh, axis=-2)\n",
    "            s = self.ws(torch.cat([s, vn], -1))\n",
    "            if self.vo: \n",
    "                v = self.wv(vh) \n",
    "                v = torch.transpose(v, -1, -2)\n",
    "                if self.vector_gate: \n",
    "                    if self.vector_act:\n",
    "                        gate = self.wsv(self.vector_act(s))\n",
    "                    else:\n",
    "                        gate = self.wsv(s)\n",
    "                    v = v * torch.sigmoid(gate).unsqueeze(-1)\n",
    "                elif self.vector_act:\n",
    "                    v = v * self.vector_act(\n",
    "                        _norm_no_nan(v, axis=-1, keepdims=True))\n",
    "        else:\n",
    "            s = self.ws(x)\n",
    "            if self.vo:\n",
    "                v = torch.zeros(s.shape[0], self.vo, 3,\n",
    "                                device=self.dummy_param.device)\n",
    "        if self.scalar_act:\n",
    "            s = self.scalar_act(s)\n",
    "        \n",
    "        return (s, v) if self.vo else s\n",
    "\n",
    "\n",
    "class GVPConv(MessagePassing):\n",
    "    '''\n",
    "    Graph convolution / message passing with Geometric Vector Perceptrons.\n",
    "    Takes in a graph with node and edge embeddings,\n",
    "    and returns new node embeddings.\n",
    "    \n",
    "    This does NOT do residual updates and pointwise feedforward layers\n",
    "    ---see `GVPConvLayer`.\n",
    "    \n",
    "    :param in_dims: input node embedding dimensions (n_scalar, n_vector)\n",
    "    :param out_dims: output node embedding dimensions (n_scalar, n_vector)\n",
    "    :param edge_dims: input edge embedding dimensions (n_scalar, n_vector)\n",
    "    :param n_layers: number of GVPs in the message function\n",
    "    :param module_list: preconstructed message function, overrides n_layers\n",
    "    :param aggr: should be \"add\" if some incoming edges are masked, as in\n",
    "                 a masked autoregressive decoder architecture, otherwise \"mean\"\n",
    "    :param activations: tuple of functions (scalar_act, vector_act) to use in GVPs\n",
    "    :param vector_gate: whether to use vector gating.\n",
    "                        (vector_act will be used as sigma^+ in vector gating if `True`)\n",
    "    '''\n",
    "    def __init__(self, in_dims, out_dims, edge_dims,\n",
    "                 n_layers=3, module_list=None, aggr=\"mean\", \n",
    "                 activations=(F.relu, torch.sigmoid), vector_gate=False):\n",
    "        super(GVPConv, self).__init__(aggr=aggr)\n",
    "        self.si, self.vi = in_dims\n",
    "        self.so, self.vo = out_dims\n",
    "        self.se, self.ve = edge_dims\n",
    "        \n",
    "        GVP_ = functools.partial(GVP, \n",
    "                activations=activations, vector_gate=vector_gate)\n",
    "        \n",
    "        module_list = module_list or []\n",
    "        if not module_list:\n",
    "            if n_layers == 1:\n",
    "                module_list.append(\n",
    "                    GVP_((2*self.si + self.se, 2*self.vi + self.ve), \n",
    "                        (self.so, self.vo), activations=(None, None)))\n",
    "            else:\n",
    "                module_list.append(\n",
    "                    GVP_((2*self.si + self.se, 2*self.vi + self.ve), out_dims)\n",
    "                )\n",
    "                for i in range(n_layers - 2):\n",
    "                    module_list.append(GVP_(out_dims, out_dims))\n",
    "                module_list.append(GVP_(out_dims, out_dims,\n",
    "                                       activations=(None, None)))\n",
    "        self.message_func = nn.Sequential(*module_list)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        '''\n",
    "        :param x: tuple (s, V) of `torch.Tensor`\n",
    "        :param edge_index: array of shape [2, n_edges]\n",
    "        :param edge_attr: tuple (s, V) of `torch.Tensor`\n",
    "        '''\n",
    "        x_s, x_v = x\n",
    "        message = self.propagate(edge_index, \n",
    "                    s=x_s, v=x_v.reshape(x_v.shape[0], 3*x_v.shape[1]),\n",
    "                    edge_attr=edge_attr)\n",
    "        return _split(message, self.vo) \n",
    "\n",
    "    def message(self, s_i, v_i, s_j, v_j, edge_attr):\n",
    "        v_j = v_j.view(v_j.shape[0], v_j.shape[1]//3, 3)\n",
    "        v_i = v_i.view(v_i.shape[0], v_i.shape[1]//3, 3)\n",
    "        message = tuple_cat((s_j, v_j), edge_attr, (s_i, v_i))\n",
    "        message = self.message_func(message)\n",
    "        return _merge(*message)\n",
    "\n",
    "class GVPConvLayer(nn.Module):\n",
    "    '''\n",
    "    Full graph convolution / message passing layer with \n",
    "    Geometric Vector Perceptrons. Residually updates node embeddings with\n",
    "    aggregated incoming messages, applies a pointwise feedforward \n",
    "    network to node embeddings, and returns updated node embeddings.\n",
    "    \n",
    "    To only compute the aggregated messages, see `GVPConv`.\n",
    "    \n",
    "    :param node_dims: node embedding dimensions (n_scalar, n_vector)\n",
    "    :param edge_dims: input edge embedding dimensions (n_scalar, n_vector)\n",
    "    :param n_message: number of GVPs to use in message function\n",
    "    :param n_feedforward: number of GVPs to use in feedforward function\n",
    "    :param drop_rate: drop probability in all dropout layers\n",
    "    :param autoregressive: if `True`, this `GVPConvLayer` will be used\n",
    "           with a different set of input node embeddings for messages\n",
    "           where src >= dst\n",
    "    :param activations: tuple of functions (scalar_act, vector_act) to use in GVPs\n",
    "    :param vector_gate: whether to use vector gating.\n",
    "                        (vector_act will be used as sigma^+ in vector gating if `True`)\n",
    "    '''\n",
    "    def __init__(self, node_dims, edge_dims,\n",
    "                 n_message=3, n_feedforward=2, drop_rate=.1,\n",
    "                 autoregressive=False, \n",
    "                 activations=(F.relu, torch.sigmoid), vector_gate=False):\n",
    "        \n",
    "        super(GVPConvLayer, self).__init__()\n",
    "        self.conv = GVPConv(node_dims, node_dims, edge_dims, n_message,\n",
    "                           aggr=\"add\" if autoregressive else \"mean\",\n",
    "                           activations=activations, vector_gate=vector_gate)\n",
    "        GVP_ = functools.partial(GVP, \n",
    "                activations=activations, vector_gate=vector_gate)\n",
    "        self.norm = nn.ModuleList([LayerNorm(node_dims) for _ in range(2)])\n",
    "        self.dropout = nn.ModuleList([Dropout(drop_rate) for _ in range(2)])\n",
    "\n",
    "        ff_func = []\n",
    "        if n_feedforward == 1:\n",
    "            ff_func.append(GVP_(node_dims, node_dims, activations=(None, None)))\n",
    "        else:\n",
    "            hid_dims = 4*node_dims[0], 2*node_dims[1]\n",
    "            ff_func.append(GVP_(node_dims, hid_dims))\n",
    "            for i in range(n_feedforward-2):\n",
    "                ff_func.append(GVP_(hid_dims, hid_dims))\n",
    "            ff_func.append(GVP_(hid_dims, node_dims, activations=(None, None)))\n",
    "        self.ff_func = nn.Sequential(*ff_func)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr,\n",
    "                autoregressive_x=None, node_mask=None):\n",
    "        '''\n",
    "        :param x: tuple (s, V) of `torch.Tensor`\n",
    "        :param edge_index: array of shape [2, n_edges]\n",
    "        :param edge_attr: tuple (s, V) of `torch.Tensor`\n",
    "        :param autoregressive_x: tuple (s, V) of `torch.Tensor`. \n",
    "                If not `None`, will be used as src node embeddings\n",
    "                for forming messages where src >= dst. The corrent node \n",
    "                embeddings `x` will still be the base of the update and the \n",
    "                pointwise feedforward.\n",
    "        :param node_mask: array of type `bool` to index into the first\n",
    "                dim of node embeddings (s, V). If not `None`, only\n",
    "                these nodes will be updated.\n",
    "        '''\n",
    "        \n",
    "        if autoregressive_x is not None:\n",
    "            src, dst = edge_index\n",
    "            mask = src < dst\n",
    "            edge_index_forward = edge_index[:, mask]\n",
    "            edge_index_backward = edge_index[:, ~mask]\n",
    "            edge_attr_forward = tuple_index(edge_attr, mask)\n",
    "            edge_attr_backward = tuple_index(edge_attr, ~mask)\n",
    "            \n",
    "            dh = tuple_sum(\n",
    "                self.conv(x, edge_index_forward, edge_attr_forward),\n",
    "                self.conv(autoregressive_x, edge_index_backward, edge_attr_backward)\n",
    "            )\n",
    "            \n",
    "            count = scatter_add(torch.ones_like(dst), dst,\n",
    "                        dim_size=dh[0].size(0)).clamp(min=1).unsqueeze(-1)\n",
    "            \n",
    "            dh = dh[0] / count, dh[1] / count.unsqueeze(-1)\n",
    "\n",
    "        else:\n",
    "            dh = self.conv(x, edge_index, edge_attr)\n",
    "        \n",
    "        if node_mask is not None:\n",
    "            x_ = x\n",
    "            x, dh = tuple_index(x, node_mask), tuple_index(dh, node_mask)\n",
    "            \n",
    "        x = self.norm[0](tuple_sum(x, self.dropout[0](dh)))\n",
    "        \n",
    "        dh = self.ff_func(x)\n",
    "        x = self.norm[1](tuple_sum(x, self.dropout[1](dh)))\n",
    "        \n",
    "        if node_mask is not None:\n",
    "            x_[0][node_mask], x_[1][node_mask] = x[0], x[1]\n",
    "            x = x_\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_gvp_res_prefs(wt_seq='',\n",
    "                      protein_name ='protein',\n",
    "                     chain_number='',\n",
    "                     pdb_din='',\n",
    "                     lmdb_dout='',\n",
    "                      model_weight_path = '../data/coves/res_weights/RES_1646945484.3030427_8.pt',\n",
    "                      dout = './', \n",
    "                      max_pos_to_do = 1000,\n",
    "                      n_ave = 15\n",
    "                     ):\n",
    "    \n",
    "    # uses RES GVP to calculate residue preferences from structural environment\n",
    "    # pdb_din: input directory of pdb file\n",
    "    # lmdb_dout: output directory for making lmdb file\n",
    "\n",
    "    ##############################################################################\n",
    "    # create list of positions that are of interest\n",
    "    pos_oi_all = list(zip([chain_number]* len(wt_seq),\n",
    "                         range(1,len(wt_seq)+1),\n",
    "                         [AA1_TO_AA3[aa] for aa in wt_seq]\n",
    "                        )\n",
    "                    )\n",
    "    # Load dataset from directory of PDB files \n",
    "    # this is recursive, all pdb files in subdirectories will also be used\n",
    "    dataset = da.load_dataset(pdb_din, 'pdb', \n",
    "                              transform = myResTransform(balance=False, pos_oi =pos_oi_all)) \n",
    "\n",
    "    # Create LMDB dataset from PDB dataset, and write to file\n",
    "    da.make_lmdb_dataset(dataset, lmdb_dout)\n",
    "    \n",
    "    ########################## LOAD MODEL #######################################\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    # push the model to cuda \n",
    "    model = get_model('RES').to(device)\n",
    "\n",
    "    #load model\n",
    "    if device == 'cuda':\n",
    "        model.load_state_dict(torch.load(model_weight_path))\n",
    "    else:\n",
    "        model.load_state_dict(torch.load(model_weight_path, map_location=torch.device('cpu')))\n",
    "\n",
    "    model = model.eval()\n",
    "    \n",
    "    ds_all = myRESDataset(lmdb_dout, chain_id_oi=chain_number)\n",
    "    dl_all = torch_geometric.data.DataLoader(ds_all, num_workers=4, batch_size=1)\n",
    "    \n",
    "    ########################## predicting mutation preferences ##################\n",
    "    df_result = pd.DataFrame()\n",
    "    with torch.no_grad():\n",
    "        c=0\n",
    "        for d in tqdm.tqdm(dl_all):\n",
    "            num, aa, b = d\n",
    "            if c<max_pos_to_do:\n",
    "                pos = num.numpy()[0]\n",
    "                aa3 = num_to_aa3[aa.numpy()[0]]\n",
    "                x= np.zeros([n_ave, 20])\n",
    "                for i in range(n_ave):\n",
    "                    out = forward(model, b, device)\n",
    "                    m_out= out.cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "                    x[i,:] = m_out\n",
    "\n",
    "                mean_x = x.mean(axis=0)\n",
    "                std_x = x.std(axis=0)\n",
    "\n",
    "                aa1 = AA3_TO_AA1[aa3]\n",
    "                wt_pos = aa1+str(pos)\n",
    "\n",
    "                muts = [wt_pos+AA3_TO_AA1[k] for k in aa3_to_num.keys()]\n",
    "\n",
    "                zipped = list(zip(muts, mean_x, std_x))\n",
    "                df_pos = pd.DataFrame(zipped, columns=['mut', 'mean_x', 'std_x'])\n",
    "\n",
    "                df_result = pd.concat([df_result,df_pos], axis=0)\n",
    "                c+=1\n",
    "                print(c)\n",
    "    df_result = df_result.reset_index()\n",
    "    #print(df_result)\n",
    "    df_result.to_csv(dout+'gvp_{}_m_{}_230523_.csv'.format(n_ave, protein_name))\n",
    "    return df_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atom3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
